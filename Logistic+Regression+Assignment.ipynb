{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Vinit Girkar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.datasets as ds\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "style.use('ggplot')\n",
    "%matplotlib inline\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy is library for scientific computing in Python. It has efficient implementation of n-dimensional array (tensor) manupulations, which is useful for machine learning applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can convert a list into numpy array (tensor)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 4],\n",
       "       [2, 6, 9]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = [[1, 2, 4], [2, 6, 9]]\n",
    "a = np.array(b)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the dimensions of the array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can apply simple arithmetic operation on all element of a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3,  6, 12],\n",
       "       [ 6, 18, 27]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a * 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can transpose a tensor\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [2, 6],\n",
       "       [4, 9]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(a.T.shape)\n",
    "a.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can apply aggregate functions on the whole tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or on one dimension of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  8, 13])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(a, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7, 17])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(a, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do element-wise arithmetic operation on two tensors (of the same size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2,  6, 20],\n",
       "       [ 2, 12,  9]])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1 = np.array([[1, 2, 4], [2, 6, 9]])\n",
    "c2 = np.array([[2, 3, 5], [1, 2, 1]])\n",
    "c1 * c2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to multiply all columns of a tensor by vector (for example if you want to multiply all data features by their lables) you need a trick. This multiplication shows up in calculating the gradients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 4]\n",
      " [2 6 9]]\n",
      "[ 1 -1]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1, 2, 4], [2, 6, 9]])\n",
    "b = np.array([1,-1])\n",
    "print(a)\n",
    "print(b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we want to multiply the first row of a by 1 and the second row of a by -1. Simply multiplying a by b does not work because a and b do not have the same dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a * b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do this multiplication we first have to assume b has one column and then repeat the column of b with the number of columns in a. We use tile function to do that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1,  1,  1],\n",
       "       [-1, -1, -1]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_repeat = np.tile(b,  (a.shape[1],1)).T\n",
    "print(b_repeat.shape)\n",
    "b_repeat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can multiply each column of a by b:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  4],\n",
       "       [-2, -6, -9]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a * b_repeat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can create inital random vector using numpy (using N(0,1)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = 0 #mean\n",
    "sigma = 1 #standard deviation\n",
    "r = np.random.normal(mu,sigma, 1000) #draws 1000 samples from a normal distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can apply functions on tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implementation of Normal distribution\n",
    "def normal(x, mu, sigma):\n",
    "    return np.exp( -0.5 * ((x-mu)/sigma)**2)/np.sqrt(2.0*np.pi*sigma**2)\n",
    "\n",
    "#probability of samples on the Normal distribution\n",
    "probabilities = normal(r, mu, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy has useful APIs for analysis. Here we plot the histogram of samples and also plot the probabilies to see if the samples follow the normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x22e72f236a0>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "counts, bins = np.histogram(r,50,density=True)\n",
    "plt.hist(bins[:-1], bins, weights=counts)\n",
    "plt.scatter(r, probabilities, c='b', marker='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    f = open(filename, 'r')\n",
    "    p = re.compile(',')\n",
    "    xdata = []\n",
    "    ydata = []\n",
    "    header = f.readline().strip()\n",
    "    varnames = p.split(header)\n",
    "    namehash = {}\n",
    "    for l in f:\n",
    "        li = p.split(l.strip())\n",
    "        xdata.append([float(x) for x in li[:-1]])\n",
    "        ydata.append(float(li[-1]))\n",
    "    \n",
    "    return np.array(xdata), np.array(ydata)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming our data is x is available in numpy we use numpy to implement logistic regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "(xtrain_whole, ytrain_whole) = read_data('/Users/acer pc/Downloads/datasets/spambase-train.csv')\n",
    "(xtest, ytest) = read_data('/Users/acer pc/Downloads/datasets/spambase-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of xtrain: (3601, 54)\n",
      "The shape of ytrain: (3601,)\n",
      "The shape of xtest: (1000, 54)\n",
      "The shape of ytest: (1000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"The shape of xtrain:\", xtrain_whole.shape)\n",
    "print(\"The shape of ytrain:\", ytrain_whole.shape)\n",
    "print(\"The shape of xtest:\", xtest.shape)\n",
    "print(\"The shape of ytest:\", ytest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "before training make we normalize the input data (features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmean = np.mean(xtrain_whole, axis=0)\n",
    "xstd = np.std(xtrain_whole, axis=0)\n",
    "xtrain_normal_whole = (xtrain_whole-xmean) / xstd\n",
    "xtest_normal = (xtest-xmean) / xstd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to create a validation set. We create an array of indecies and permute it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "premute_indicies = np.random.permutation(np.arange(xtrain_whole.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We keep the first 2600 data points as the training data and rest as the validation data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_normal = xtrain_normal_whole[premute_indicies[:2600]]\n",
    "ytrain = ytrain_whole[premute_indicies[:2600]]\n",
    "xval_normal = xtrain_normal_whole[premute_indicies[2600:]]\n",
    "yval = ytrain_whole[premute_indicies[2600:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initiallizing the weights and bias with random values from N(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.random.normal(0, 1, xtrain_normal.shape[1]);\n",
    "bias = np.random.normal(0,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the sigmoid function\n",
    "def sigmoid(v):\n",
    "    #return np.exp(-np.logaddexp(0, -v)) #numerically stable implementation of sigmoid function\n",
    "    ret = 1. / (1.+np.exp(-v))\n",
    "    #type(ret)\n",
    "    return ret\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use dot-product from numpy to calculate the margin and pass it to the sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#w: weight vector (numpy array of size n)\n",
    "#b: numpy array of size 1\n",
    "#returns p(y=1|x, w, b)\n",
    "def prob(x, w, b):\n",
    "    #print((np.dot(x,w) + b).shape)\n",
    "    return sigmoid(np.dot(x,w) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also calculate $l_2$ penalty using linalg library of numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.403097022994158"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\text{Cross Entropy Loss} = -\\sum_{(y^i,\\mathbf{x}^i)\\in\\mathcal{D}} \n",
    " y^i \\log p(y=1|\\mathbf{x}^i;\\mathbf{w},b)  +  (1-y^i) \\log (1 - p(y=1|\\mathbf{x}^i;\\mathbf{w},b)+\\frac{\\lambda}{2} \\|\\mathbf{w}\\|^2 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#w: weight vector (numpy array of size n)\n",
    "#y_prob: p(y|x, w, b)\n",
    "#y_true: class variable data\n",
    "#lambda_: l2 penalty coefficient\n",
    "#returns the cross entropy loss\n",
    "def loss(w, y_prob, y_true, lambda_):\n",
    "    cel = -np.sum(np.dot(y_true, np.log(y_prob)) - (np.dot((1 - y_true), np.log(1 - y_prob)))) + (lambda_/2) * ((np.linalg.norm(weights)) ** 2)\n",
    "    return cel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x: input variables (data of size m x n with m data point and n features)\n",
    "#w: weight vector (numpy array of size n)\n",
    "#y_prob: p(y|x, w, b)\n",
    "#y_true: class variable data\n",
    "#lambda_: l2 penalty coefficient\n",
    "#returns tuple of gradient w.r.t w and w.r.t to bias\n",
    "\n",
    "def grad_w_b(x, w, y_prob, y_true, lambda_):\n",
    "    a,b = x.shape\n",
    "    grad_w = np.zeros(w.shape)\n",
    "    grad_b = 0.0\n",
    "    grad_w = (1/a) * (np.dot(x.T, (y_prob - y_true)) + (lambda_ * np.linalg.norm(w)))\n",
    "    grad_b = (1/b) * np.sum(y_prob - y_true)\n",
    "    return (grad_w,grad_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#lambda_ is the coeffienct of l2 norm penalty\n",
    "#learning_rate is learning rate of gradient descent algorithm\n",
    "#max_iter determines the maximum number of iterations if the gradients descent does not converge.\n",
    "#continue the training while gradient > 0.1 or the number steps is less max_iter\n",
    "\n",
    "#returns model as tuple of (weights,bias)\n",
    "\n",
    "def fit(x, y_true, learning_rate, lambda_, max_iter, verbose=0):\n",
    "    weights = np.random.normal(0, 1, x.shape[1])\n",
    "    bias = np.random.normal(0,1,1)\n",
    "    steps = 0\n",
    "    gw = weights\n",
    "    gb = bias\n",
    "    #raise NotImplementedError\n",
    "    \n",
    "    while (gw.all() > 0.1) and (steps < max_iter):\n",
    "        (grad_weights, grad_bias) = grad_w_b(x, weights, prob(x, weights, bias), y_true, lambda_)\n",
    "        temp0 = weights - (learning_rate * grad_weights)\n",
    "        temp1 = bias - (learning_rate * grad_bias)\n",
    "        gw = np.abs(temp0 - weights)\n",
    "        gb = np.abs(temp1 - bias)\n",
    "        weights = temp0\n",
    "        bias = temp1\n",
    "        steps += 1\n",
    "        \n",
    "    return (weights, bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(x, y_true, model):\n",
    "    w, b = model\n",
    "    return np.sum((prob(x, w, b)>0.5).astype(np.float) == y_true)  / y_true.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "lambda_ = 1.0\n",
    "\n",
    "model = fit(xtrain_normal, ytrain, learning_rate, lambda_, 10000, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.8484615384615385\n"
     ]
    }
   ],
   "source": [
    "print(\"Train accuracy: \", accuracy(xtrain_normal, ytrain, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 5 0.9200799200799201\n",
      "0.01 2 0.929070929070929\n",
      "0.01 1 0.9240759240759241\n",
      "0.01 0.1 0.9280719280719281\n",
      "0.01 0.01 0.9310689310689311\n",
      "0.001 5 0.8491508491508492\n",
      "0.001 2 0.8051948051948052\n",
      "0.001 1 0.8531468531468531\n",
      "0.001 0.1 0.8651348651348651\n",
      "0.001 0.01 0.8481518481518482\n",
      "0.0001 5 0.45054945054945056\n",
      "0.0001 2 0.6803196803196803\n",
      "0.0001 1 0.7052947052947053\n",
      "0.0001 0.1 0.5814185814185814\n",
      "0.0001 0.01 0.5984015984015985\n",
      "1e-05 5 0.5284715284715285\n",
      "1e-05 2 0.4945054945054945\n",
      "1e-05 1 0.6293706293706294\n",
      "1e-05 0.1 0.5804195804195804\n",
      "1e-05 0.01 0.33766233766233766\n"
     ]
    }
   ],
   "source": [
    "#grid search for finding the best hyperparams and model\n",
    "\n",
    "best_model = None\n",
    "best_val = -1\n",
    "for lr in [0.01, 0.001, 0.0001, 0.00001]:\n",
    "    for la in [5, 2, 1, 0.1, 0.01]:\n",
    "        model = fit(xtrain_normal, ytrain, lr, la, 10000)\n",
    "        val_acc = accuracy(xval_normal, yval, model)\n",
    "        print(lr, la, val_acc)\n",
    "        if val_acc > best_val:\n",
    "            best_val = val_acc\n",
    "            best_model = model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.937\n"
     ]
    }
   ],
   "source": [
    "print(\"Test accuracy: \", accuracy(xtest_normal, ytest, best_model))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
